{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. üì• Clone GitHub Repository"
      ],
      "metadata": {
        "id": "nGqgMsFvdNs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 1: Clone PhonePe Pulse GitHub Repository\n",
        "!git clone https://github.com/PhonePe/pulse.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KHlSni6dSk7",
        "outputId": "78748c86-1aa1-40cc-ca6d-86192afbc107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pulse'...\n",
            "remote: Enumerating objects: 17904, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 17904 (delta 19), reused 17 (delta 17), pack-reused 17855 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17904/17904), 26.13 MiB | 7.74 MiB/s, done.\n",
            "Resolving deltas: 100% (8723/8723), done.\n",
            "Updating files: 100% (9029/9029), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. üì¶ Install Required Libraries"
      ],
      "metadata": {
        "id": "Ex1sSpbudT3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 2: Install Required Libraries\n",
        "!pip install pandas matplotlib seaborn streamlit plotly openpyxl -q"
      ],
      "metadata": {
        "id": "c8zqOfxIdVnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3338024-9b32-466d-8a70-805d238e80ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. üìÇ Import Libraries and Setup Paths"
      ],
      "metadata": {
        "id": "pXc-1VK7dYgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 3: Import Libraries and Define Paths\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "\n",
        "# Set paths\n",
        "DATA_DIR = 'pulse/data'\n",
        "AGGREGATED_DIR = os.path.join(DATA_DIR, 'aggregated')\n",
        "MAP_DIR = os.path.join(DATA_DIR, 'map')\n",
        "TOP_DIR = os.path.join(DATA_DIR, 'top')\n",
        "\n",
        "print(\"Paths set up successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMklii7ddY9L",
        "outputId": "642a1ba1-15c0-4e6c-fba1-873d63325aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paths set up successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. üîÑ ETL Functions to Load Data\n",
        "Create etl.py file inside /src/"
      ],
      "metadata": {
        "id": "hMkqMRB4desi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File: src/etl.py\n",
        "\n",
        "def load_json_files(base_path):\n",
        "    \"\"\"Load all JSON files from a given directory.\"\"\"\n",
        "    all_data = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        data = json.load(f)\n",
        "                        # Add metadata about path\n",
        "                        year = os.path.basename(os.path.dirname(root))\n",
        "                        quarter = os.path.splitext(file)[0]\n",
        "                        data['metadata'] = {'year': year, 'quarter': quarter}\n",
        "                        all_data.append(data)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def extract_transaction_data(data_list):\n",
        "    \"\"\"Extract transaction data from loaded JSON.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        for entry in data.get('data', {}).get('transactionData', []):\n",
        "            category = entry.get('name', '')\n",
        "            for instrument in entry.get('paymentInstruments', []):\n",
        "                records.append({\n",
        "                    'category': category,\n",
        "                    'count': instrument.get('count', 0),\n",
        "                    'amount': instrument.get('amount', 0),\n",
        "                    'year': meta.get('year'),\n",
        "                    'quarter': meta.get('quarter')\n",
        "                })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_user_device_data(data_list):\n",
        "    \"\"\"Extract user device data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        aggregated = data.get('data', {}).get('aggregated', {})\n",
        "        users_by_device = data.get('data', {}).get('usersByDevice', [])\n",
        "        for device in users_by_device:\n",
        "            records.append({\n",
        "                'device_brand': device.get('brand'),\n",
        "                'registered_users': device.get('count'),\n",
        "                'percentage': device.get('percentage'),\n",
        "                'total_registered_users': aggregated.get('registeredUsers', 0),\n",
        "                'app_opens': aggregated.get('appOpens', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_map_transaction_data(data_list):\n",
        "    \"\"\"Extract map-level transaction data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        hover_list = data.get('data', {}).get('hoverDataList', [])\n",
        "        for item in hover_list:\n",
        "            name = item.get('name', '').title()\n",
        "            metric = item.get('metric', [{}])[0]\n",
        "            records.append({\n",
        "                'state_district': name,\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_top_states_data(data_list):\n",
        "    \"\"\"Extract top states by transaction volume.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        states = data.get('data', {}).get('states', [])\n",
        "        for state in states:\n",
        "            metric = state.get('metric', {})\n",
        "            records.append({\n",
        "                'state': state.get('entityName', '').title(),\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "dGo_u7qhdgQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. üìä Load All Data into DataFrames"
      ],
      "metadata": {
        "id": "jAfoFGe-dpPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step A.1: Create Required Folders\n",
        "import os\n",
        "\n",
        "os.makedirs('src', exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Folder structure created: src/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcJnvIKBev9d",
        "outputId": "3dcc4f86-b123-49a1-b687-113a65e555b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Folder structure created: src/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step A: Create `etl.py` file\n",
        "%%writefile src/etl.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_json_files(base_path):\n",
        "    \"\"\"Load all JSON files from a given directory.\"\"\"\n",
        "    all_data = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        data = json.load(f)\n",
        "                        # Add metadata about path\n",
        "                        year = os.path.basename(os.path.dirname(root))\n",
        "                        quarter = os.path.splitext(file)[0]\n",
        "                        data['metadata'] = {'year': year, 'quarter': quarter}\n",
        "                        all_data.append(data)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def extract_transaction_data(data_list):\n",
        "    \"\"\"Extract transaction data from loaded JSON.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        for entry in data.get('data', {}).get('transactionData', []):\n",
        "            category = entry.get('name', '')\n",
        "            for instrument in entry.get('paymentInstruments', []):\n",
        "                records.append({\n",
        "                    'category': category,\n",
        "                    'count': instrument.get('count', 0),\n",
        "                    'amount': instrument.get('amount', 0),\n",
        "                    'year': meta.get('year'),\n",
        "                    'quarter': meta.get('quarter')\n",
        "                })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_user_device_data(data_list):\n",
        "    \"\"\"Extract user device data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        aggregated = data.get('data', {}).get('aggregated', {})\n",
        "        users_by_device = data.get('data', {}).get('usersByDevice', [])\n",
        "        for device in users_by_device:\n",
        "            records.append({\n",
        "                'device_brand': device.get('brand'),\n",
        "                'registered_users': device.get('count'),\n",
        "                'percentage': device.get('percentage'),\n",
        "                'total_registered_users': aggregated.get('registeredUsers', 0),\n",
        "                'app_opens': aggregated.get('appOpens', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_map_transaction_data(data_list):\n",
        "    \"\"\"Extract map-level transaction data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        hover_list = data.get('data', {}).get('hoverDataList', [])\n",
        "        for item in hover_list:\n",
        "            name = item.get('name', '').title()\n",
        "            metric = item.get('metric', [{}])[0]\n",
        "            records.append({\n",
        "                'state_district': name,\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_top_states_data(data_list):\n",
        "    \"\"\"Extract top states by transaction volume.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        states = data.get('data', {}).get('states', [])\n",
        "        for state in states:\n",
        "            metric = state.get('metric', {})\n",
        "            records.append({\n",
        "                'state': state.get('entityName', '').title(),\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aub7XS9mei3c",
        "outputId": "2ea5f25d-458e-4294-d899-6ba041d89444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/etl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step A.1: Create Folder Structure (src/)\n",
        "import os\n",
        "\n",
        "os.makedirs('src', exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Created folder: src/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDvaXUM1fC68",
        "outputId": "18fe8988-9124-4ab6-e0d8-64dbf8d469c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created folder: src/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step A.2: Write ETL Module to src/etl.py\n",
        "%%writefile src/etl.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_json_files(base_path):\n",
        "    \"\"\"Load all JSON files from a given directory.\"\"\"\n",
        "    all_data = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        data = json.load(f)\n",
        "                        # Add metadata about path\n",
        "                        year = os.path.basename(os.path.dirname(root))\n",
        "                        quarter = os.path.splitext(file)[0]\n",
        "                        data['metadata'] = {'year': year, 'quarter': quarter}\n",
        "                        all_data.append(data)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def extract_transaction_data(data_list):\n",
        "    \"\"\"Extract transaction data from loaded JSON.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        for entry in data.get('data', {}).get('transactionData', []):\n",
        "            category = entry.get('name', '')\n",
        "            for instrument in entry.get('paymentInstruments', []):\n",
        "                records.append({\n",
        "                    'category': category,\n",
        "                    'count': instrument.get('count', 0),\n",
        "                    'amount': instrument.get('amount', 0),\n",
        "                    'year': meta.get('year'),\n",
        "                    'quarter': meta.get('quarter')\n",
        "                })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_user_device_data(data_list):\n",
        "    \"\"\"Extract user device data with robust error handling.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        try:\n",
        "            # Ensure metadata exists\n",
        "            meta = data.get(\"metadata\", {})\n",
        "\n",
        "            # Safely get data[\"data\"] with fallback\n",
        "            if not isinstance(data, dict):\n",
        "                continue  # Skip non-dictionary items\n",
        "\n",
        "            data_content = data.get(\"data\")\n",
        "\n",
        "            if not (isinstance(data_content, dict) and data_content):\n",
        "                continue  # Skip if not a non-empty dictionary\n",
        "\n",
        "            aggregated = data_content.get(\"aggregated\", {})\n",
        "            users_by_device = data_content.get(\"usersByDevice\", []) or []\n",
        "\n",
        "            for device in users_by_device:\n",
        "                records.append({\n",
        "                    \"device_brand\": device.get(\"brand\"),\n",
        "                    \"registered_users\": device.get(\"count\"),\n",
        "                    \"percentage\": device.get(\"percentage\"),\n",
        "                    \"total_registered_users\": aggregated.get(\"registeredUsers\", 0),\n",
        "                    \"app_opens\": aggregated.get(\"appOpens\", 0),\n",
        "                    \"year\": meta.get(\"year\"),\n",
        "                    \"quarter\": meta.get(\"quarter\"),\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing one item: {e}\")\n",
        "            continue  # Skip problematic item without breaking loop\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_map_transaction_data(data_list):\n",
        "    \"\"\"Extract map-level transaction data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        hover_list = data.get('data', {}).get('hoverDataList', [])\n",
        "        for item in hover_list:\n",
        "            name = item.get('name', '').title()\n",
        "            metric = item.get('metric', [{}])[0]\n",
        "            records.append({\n",
        "                'state_district': name,\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_top_states_data(data_list):\n",
        "    \"\"\"Extract top states by transaction volume with robust error handling.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        try:\n",
        "            meta = data.get(\"metadata\", {})\n",
        "\n",
        "            # Safely access nested data\n",
        "            if not isinstance(data, dict):\n",
        "                continue\n",
        "\n",
        "            data_content = data.get(\"data\")\n",
        "            if not (isinstance(data_content, dict) and data_content):\n",
        "                continue\n",
        "\n",
        "            states = data_content.get(\"states\")  # Could be None or non-list\n",
        "            if not isinstance(states, list):\n",
        "                states = []  # Ensure it's a list even if missing or invalid\n",
        "\n",
        "            for state in states:\n",
        "                metric = state.get(\"metric\", {})\n",
        "                records.append({\n",
        "                    \"state\": state.get(\"entityName\", \"\").title(),\n",
        "                    \"count\": metric.get(\"count\", 0),\n",
        "                    \"amount\": metric.get(\"amount\", 0),\n",
        "                    \"year\": meta.get(\"year\"),\n",
        "                    \"quarter\": meta.get(\"quarter\"),\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing item: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mth4xWXMfHFA",
        "outputId": "10b1241e-139c-4ab0-ec2c-f98ee0509288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/etl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step A.3: Check if etl.py exists\n",
        "import os\n",
        "\n",
        "if os.path.exists('src/etl.py'):\n",
        "    print(\"‚úÖ File found: src/etl.py\")\n",
        "else:\n",
        "    print(\"‚ùå File not found: src/etl.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxEirKLEfKLZ",
        "outputId": "0b9cc15b-060c-4012-84d3-accdaba97dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ File found: src/etl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Overwrite etl.py with All Fixes\n",
        "%%writefile src/etl.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_json_files(base_path):\n",
        "    \"\"\"Load all JSON files from a given directory.\"\"\"\n",
        "    all_data = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        data = json.load(f)\n",
        "                        # Add metadata about path\n",
        "                        year = os.path.basename(os.path.dirname(root))\n",
        "                        quarter = os.path.splitext(file)[0]\n",
        "                        data['metadata'] = {'year': year, 'quarter': quarter}\n",
        "                        all_data.append(data)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def extract_transaction_data(data_list):\n",
        "    \"\"\"Extract transaction data from loaded JSON.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        for entry in data.get('data', {}).get('transactionData', []):\n",
        "            category = entry.get('name', '')\n",
        "            for instrument in entry.get('paymentInstruments', []):\n",
        "                records.append({\n",
        "                    'category': category,\n",
        "                    'count': instrument.get('count', 0),\n",
        "                    'amount': instrument.get('amount', 0),\n",
        "                    'year': meta.get('year'),\n",
        "                    'quarter': meta.get('quarter')\n",
        "                })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_user_device_data(data_list):\n",
        "    \"\"\"Extract user device data with robust error handling.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        try:\n",
        "            # Ensure metadata exists\n",
        "            meta = data.get(\"metadata\", {})\n",
        "\n",
        "            # Safely get data[\"data\"] with fallback\n",
        "            if not isinstance(data, dict):\n",
        "                continue  # Skip non-dictionary items\n",
        "\n",
        "            data_content = data.get(\"data\")\n",
        "\n",
        "            if not (isinstance(data_content, dict) and data_content):\n",
        "                continue  # Skip if not a non-empty dictionary\n",
        "\n",
        "            aggregated = data_content.get(\"aggregated\", {})\n",
        "            users_by_device = data_content.get(\"usersByDevice\", []) or []\n",
        "\n",
        "            for device in users_by_device:\n",
        "                records.append({\n",
        "                    \"device_brand\": device.get(\"brand\"),\n",
        "                    \"registered_users\": device.get(\"count\"),\n",
        "                    \"percentage\": device.get(\"percentage\"),\n",
        "                    \"total_registered_users\": aggregated.get(\"registeredUsers\", 0),\n",
        "                    \"app_opens\": aggregated.get(\"appOpens\", 0),\n",
        "                    \"year\": meta.get(\"year\"),\n",
        "                    \"quarter\": meta.get(\"quarter\"),\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing one item: {e}\")\n",
        "            continue  # Skip problematic item without breaking loop\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_map_transaction_data(data_list):\n",
        "    \"\"\"Extract map-level transaction data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        hover_list = data.get('data', {}).get('hoverDataList', [])\n",
        "        for item in hover_list:\n",
        "            name = item.get('name', '').title()\n",
        "            metric = item.get('metric', [{}])[0]\n",
        "            records.append({\n",
        "                'state_district': name,\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_top_states_data(data_list):\n",
        "    \"\"\"Extract top states by transaction volume with robust error handling.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        try:\n",
        "            meta = data.get(\"metadata\", {})\n",
        "\n",
        "            # Safely access nested data\n",
        "            if not isinstance(data, dict):\n",
        "                continue\n",
        "\n",
        "            data_content = data.get(\"data\")\n",
        "            if not (isinstance(data_content, dict) and data_content):\n",
        "                continue\n",
        "\n",
        "            states = data_content.get(\"states\")\n",
        "            if not isinstance(states, list):\n",
        "                states = []\n",
        "\n",
        "            for state in states:\n",
        "                metric = state.get(\"metric\", {})\n",
        "                records.append({\n",
        "                    \"state\": state.get(\"entityName\", \"\").title(),\n",
        "                    \"count\": metric.get(\"count\", 0),\n",
        "                    \"amount\": metric.get(\"amount\", 0),\n",
        "                    \"year\": meta.get(\"year\"),\n",
        "                    \"quarter\": meta.get(\"quarter\"),\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing item: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2VKJOC-QoBx",
        "outputId": "87167ae9-beeb-4be0-858d-4ff0e687a90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/etl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step: Import ETL Module Again\n",
        "import sys\n",
        "sys.path.append(\"src\")\n",
        "\n",
        "try:\n",
        "    from etl import load_json_files, extract_transaction_data, extract_user_device_data, extract_map_transaction_data, extract_top_states_data\n",
        "    print(\"‚úÖ Successfully imported functions from etl.py\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error:\", str(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I2BjQ5BQr1E",
        "outputId": "5a32530d-735b-47c8-e879-d9a640f77fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully imported functions from etl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step: Import ETL Module and Load Data\n",
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "# Reload the etl module after modifying it\n",
        "if 'etl' in sys.modules:\n",
        "    del sys.modules['etl']\n",
        "\n",
        "from etl import load_json_files, extract_transaction_data, extract_user_device_data, extract_map_transaction_data, extract_top_states_data\n",
        "\n",
        "# Define base directories\n",
        "DATA_DIR = 'pulse/data'\n",
        "AGGREGATED_DIR = os.path.join(DATA_DIR, 'aggregated')\n",
        "MAP_DIR = os.path.join(DATA_DIR, 'map')\n",
        "TOP_DIR = os.path.join(DATA_DIR, 'top')\n",
        "\n",
        "# --- Load Aggregated Transaction Data ---\n",
        "agg_trans_data = load_json_files(os.path.join(AGGREGATED_DIR, 'transaction'))\n",
        "df_agg_transactions = extract_transaction_data(agg_trans_data)\n",
        "\n",
        "# --- Load Aggregated User Device Data ---\n",
        "agg_user_data = load_json_files(os.path.join(AGGREGATED_DIR, 'user'))\n",
        "df_agg_users = extract_user_device_data(agg_user_data)\n",
        "\n",
        "# --- Load Map-Level Transaction Data ---\n",
        "map_trans_data = load_json_files(os.path.join(MAP_DIR, 'transaction'))\n",
        "df_map_transactions = extract_map_transaction_data(map_trans_data)\n",
        "\n",
        "# --- Load Top States by Transaction Volume ---\n",
        "top_trans_data = load_json_files(os.path.join(TOP_DIR, 'transaction'))\n",
        "df_top_states = extract_top_states_data(top_trans_data)\n",
        "\n",
        "print(\"‚úÖ All data loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRccwriDfPHS",
        "outputId": "6fc3cc8f-db14-4220-efb0-2911c46c1a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All data loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 4: Load All Data into Pandas DataFrames\n",
        "import sys\n",
        "sys.path.append('src/')\n",
        "from etl import *\n",
        "\n",
        "# Load Aggregated Transaction Data\n",
        "agg_trans_data = load_json_files(os.path.join(AGGREGATED_DIR, 'transaction'))\n",
        "df_agg_transactions = extract_transaction_data(agg_trans_data)\n",
        "\n",
        "# Load User Device Data\n",
        "agg_user_data = load_json_files(os.path.join(AGGREGATED_DIR, 'user'))\n",
        "df_agg_users = extract_user_device_data(agg_user_data)\n",
        "\n",
        "# Load Map Transaction Data\n",
        "map_trans_data = load_json_files(os.path.join(MAP_DIR, 'transaction'))\n",
        "df_map_transactions = extract_map_transaction_data(map_trans_data)\n",
        "\n",
        "# Load Top States Data\n",
        "top_trans_data = load_json_files(os.path.join(TOP_DIR, 'transaction'))\n",
        "df_top_states = extract_top_states_data(top_trans_data)\n",
        "\n",
        "print(\"All dataframes loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P604u43Zdp7F",
        "outputId": "4fe7ea17-629c-4ec4-ac5b-57f24d8ed549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataframes loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. üìà Data Analysis and Visualization"
      ],
      "metadata": {
        "id": "IWw64mOKdtsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step A.4: Create src/visualization.py (Fully Streamlit-Compatible)\n",
        "# @title Final Fixed src/visualization.py\n",
        "%%writefile src/visualization.py\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "\n",
        "# Color scheme\n",
        "PHONEPE_PURPLE = \"#5F0F40\"\n",
        "PHONEPE_RED = \"#9A031E\"\n",
        "PHONEPE_ORANGE = \"#FB8B24\"\n",
        "PHONEPE_DARK_ORANGE = \"#E36414\"\n",
        "PHONEPE_TEAL = \"#0F4C5C\"\n",
        "COLOR_SEQUENCE = [PHONEPE_PURPLE, PHONEPE_RED, PHONEPE_ORANGE, PHONEPE_DARK_ORANGE, PHONEPE_TEAL]\n",
        "\n",
        "# Dark text colors for readability\n",
        "TEXT_COLOR = \"#333333\"\n",
        "AXIS_COLOR = \"#555555\"\n",
        "GRID_COLOR = \"#e0e0e0\"\n",
        "\n",
        "def apply_plot_style(fig, title):\n",
        "    fig.update_layout(\n",
        "        plot_bgcolor='rgba(255, 255, 255, 0.5)',\n",
        "        paper_bgcolor='rgba(255, 255, 255, 0.5)',\n",
        "        title={\n",
        "            'text': f\"<b>{title}</b>\",\n",
        "            'font': {'size': 18, 'color': PHONEPE_PURPLE},\n",
        "            'x': 0.05,\n",
        "            'xanchor': 'left'\n",
        "        },\n",
        "        font={'color': TEXT_COLOR},\n",
        "        xaxis={\n",
        "            'color': AXIS_COLOR,\n",
        "            'gridcolor': GRID_COLOR,\n",
        "            'title_font': {'size': 14}\n",
        "        },\n",
        "        yaxis={\n",
        "            'color': AXIS_COLOR,\n",
        "            'gridcolor': GRID_COLOR,\n",
        "            'title_font': {'size': 14}\n",
        "        },\n",
        "        legend={\n",
        "            'font': {'size': 12},\n",
        "            'title_font': {'size': 13}\n",
        "        },\n",
        "        hoverlabel={\n",
        "            'bgcolor': 'white',\n",
        "            'font_size': 12,\n",
        "            'font_family': \"Arial\",\n",
        "            'bordercolor': PHONEPE_PURPLE\n",
        "        },\n",
        "        margin={'l': 50, 'r': 30, 't': 70, 'b': 50},\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def plot_transaction_trend(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby('period')[['count', 'amount']].sum().reset_index()\n",
        "\n",
        "    fig = px.line(grouped, x='period', y='count',\n",
        "                 title=\"Transaction Trend Over Time\",\n",
        "                 labels={'count': 'Transaction Count', 'period': 'Quarter'},\n",
        "                 color_discrete_sequence=[PHONEPE_PURPLE],\n",
        "                 template='plotly_white')\n",
        "\n",
        "    fig.update_traces(line_width=3, hovertemplate=\"%{y:,.0f} transactions\")\n",
        "    fig = apply_plot_style(fig, \"Transaction Trend Over Time\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# [Rest of the visualization functions follow the same pattern with the updated styling]\n",
        "\n",
        "def plot_category_distribution(df, return_fig=False):\n",
        "    grouped = df.groupby('category')[['count', 'amount']].sum().reset_index()\n",
        "\n",
        "    fig = px.bar(grouped, x='count', y='category',\n",
        "                 title=\"Transaction Distribution by Category\",\n",
        "                 labels={'count': 'Number of Transactions', 'category': 'Category'},\n",
        "                 color='category',\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Transaction Distribution by Category\")\n",
        "    fig.update_yaxes(categoryorder='total ascending')\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_top_states(df, return_fig=False):\n",
        "    grouped = df.groupby('state')[['count', 'amount']].sum().sort_values(by='count', ascending=False).head(10).reset_index()\n",
        "\n",
        "    fig = px.bar(grouped, x='count', y='state',\n",
        "                 title=\"Top 10 States by Transaction Volume\",\n",
        "                 labels={'count': 'Transaction Count', 'state': 'State'},\n",
        "                 color='state',\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Top 10 States by Transaction Volume\")\n",
        "    fig.update_yaxes(categoryorder='total ascending')\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_device_usage(df, return_fig=False):\n",
        "    grouped = df.groupby('device_brand')['registered_users'].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "\n",
        "    fig = px.pie(grouped, values='registered_users', names='device_brand',\n",
        "                 title=\"Top 10 Device Brands by User Share\",\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Top 10 Device Brands by User Share\")\n",
        "    fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_quarterly_growth(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby('period')['count'].sum().reset_index()\n",
        "    grouped['growth'] = grouped['count'].pct_change() * 100\n",
        "\n",
        "    fig = px.line(grouped, x='period', y='growth',\n",
        "                  title=\"Quarter-over-Quarter Growth Rate\",\n",
        "                  labels={'growth': 'Growth Rate (%)', 'period': 'Quarter'},\n",
        "                  color_discrete_sequence=[PHONEPE_RED])\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Quarter-over-Quarter Growth Rate\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_category_trends(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby(['period', 'category'])['count'].sum().reset_index()\n",
        "\n",
        "    fig = px.line(grouped, x='period', y='count', color='category',\n",
        "                  title=\"Category-wise Transaction Trends\",\n",
        "                  labels={'count': 'Transaction Count', 'period': 'Quarter'},\n",
        "                  color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Category-wise Transaction Trends\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_state_analysis(df, return_fig=False):\n",
        "    grouped = df.groupby('state')[['count', 'amount']].sum().reset_index()\n",
        "\n",
        "    fig = px.scatter(grouped, x='count', y='amount', color='state',\n",
        "                     size='count', hover_name='state',\n",
        "                     title=\"State-wise Transaction Volume vs Value\",\n",
        "                     labels={'count': 'Transaction Count', 'amount': 'Transaction Amount'},\n",
        "                     color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"State-wise Transaction Volume vs Value\")\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_top_districts(df, return_fig=False):\n",
        "    grouped = df.groupby('state_district')['count'].sum().sort_values(ascending=False).head(15).reset_index()\n",
        "\n",
        "    fig = px.bar(grouped, x='count', y='state_district',\n",
        "                 title=\"Top 15 Districts by Transaction Volume\",\n",
        "                 labels={'count': 'Transaction Count', 'state_district': 'District'},\n",
        "                 color='state_district',\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Top 15 Districts by Transaction Volume\")\n",
        "    fig.update_yaxes(categoryorder='total ascending')\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_user_growth(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby('period')['total_registered_users'].sum().reset_index()\n",
        "\n",
        "    fig = px.line(grouped, x='period', y='total_registered_users',\n",
        "                  title=\"Registered User Growth\",\n",
        "                  labels={'total_registered_users': 'Registered Users', 'period': 'Quarter'},\n",
        "                  color_discrete_sequence=[PHONEPE_TEAL])\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Registered User Growth\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_device_share_trend(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby(['period', 'device_brand'])['registered_users'].sum().reset_index()\n",
        "    top_brands = df.groupby('device_brand')['registered_users'].sum().sort_values(ascending=False).head(5).index\n",
        "    grouped = grouped[grouped['device_brand'].isin(top_brands)]\n",
        "\n",
        "    fig = px.area(grouped, x='period', y='registered_users', color='device_brand',\n",
        "                  title=\"Top 5 Device Brands Over Time\",\n",
        "                  labels={'registered_users': 'Registered Users', 'period': 'Quarter'},\n",
        "                  color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Top 5 Device Brands Over Time\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_transaction_heatmap(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby(['period', 'category'])['count'].sum().unstack()\n",
        "\n",
        "    fig = px.imshow(grouped,\n",
        "                   labels=dict(x=\"Category\", y=\"Quarter\", color=\"Transactions\"),\n",
        "                   title=\"Transaction Heatmap by Quarter and Category\",\n",
        "                   color_continuous_scale=[PHONEPE_PURPLE, PHONEPE_ORANGE])\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Transaction Heatmap by Quarter and Category\")\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_avg_transaction_value(df, return_fig=False):\n",
        "    grouped = df.groupby('category').agg({'count':'sum', 'amount':'sum'}).reset_index()\n",
        "    grouped['avg_value'] = grouped['amount'] / grouped['count']\n",
        "\n",
        "    fig = px.bar(grouped, x='category', y='avg_value',\n",
        "                 title=\"Average Transaction Value by Category\",\n",
        "                 labels={'avg_value': 'Average Value (‚Çπ)', 'category': 'Category'},\n",
        "                 color='category',\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Average Transaction Value by Category\")\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)"
      ],
      "metadata": {
        "id": "aG73gyuLduJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc50f81e-f48f-490c-b157-b735b3e1c0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/visualization.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. üìä Run Visualizations"
      ],
      "metadata": {
        "id": "glSIsYH4dwH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 5: Run and Save All Visualizations\n",
        "import sys\n",
        "sys.path.append('src/')\n",
        "from visualization import *\n",
        "import os\n",
        "\n",
        "# Create output directory if not exists\n",
        "os.makedirs('output', exist_ok=True)\n",
        "os.makedirs('output/visualizations', exist_ok=True)  # For saving plot images\n",
        "\n",
        "# Function to save Plotly figures as HTML for Streamlit\n",
        "def save_plotly_fig(fig, filename):\n",
        "    fig.write_html(f\"output/visualizations/{filename}.html\")\n",
        "\n",
        "# 1. Transaction Trend\n",
        "fig1 = plot_transaction_trend(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig1, \"transaction_trend\")\n",
        "\n",
        "# 2. Category Distribution\n",
        "fig2 = plot_category_distribution(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig2, \"category_distribution\")\n",
        "\n",
        "# 3. Top States\n",
        "fig3 = plot_top_states(df_top_states, return_fig=True)\n",
        "save_plotly_fig(fig3, \"top_states\")\n",
        "\n",
        "# 4. Device Usage\n",
        "fig4 = plot_device_usage(df_agg_users, return_fig=True)\n",
        "save_plotly_fig(fig4, \"device_usage\")\n",
        "\n",
        "# 5. Quarterly Growth\n",
        "fig5 = plot_quarterly_growth(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig5, \"quarterly_growth\")\n",
        "\n",
        "# 6. Category Trends\n",
        "fig6 = plot_category_trends(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig6, \"category_trends\")\n",
        "\n",
        "# 7. State Analysis\n",
        "fig7 = plot_state_analysis(df_top_states, return_fig=True)\n",
        "save_plotly_fig(fig7, \"state_analysis\")\n",
        "\n",
        "# 8. Top Districts\n",
        "fig8 = plot_top_districts(df_map_transactions, return_fig=True)\n",
        "save_plotly_fig(fig8, \"top_districts\")\n",
        "\n",
        "# 9. User Growth\n",
        "fig9 = plot_user_growth(df_agg_users, return_fig=True)\n",
        "save_plotly_fig(fig9, \"user_growth\")\n",
        "\n",
        "# 10. Device Share Trends\n",
        "fig10 = plot_device_share_trend(df_agg_users, return_fig=True)\n",
        "save_plotly_fig(fig10, \"device_share_trends\")\n",
        "\n",
        "# 11. Transaction Heatmap\n",
        "fig11 = plot_transaction_heatmap(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig11, \"transaction_heatmap\")\n",
        "\n",
        "# 12. Avg Transaction Value\n",
        "fig12 = plot_avg_transaction_value(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig12, \"avg_transaction_value\")\n",
        "\n",
        "# Save DataFrames to CSV\n",
        "df_agg_transactions.to_csv('output/agg_transactions.csv', index=False)\n",
        "df_agg_users.to_csv('output/agg_users.csv', index=False)\n",
        "df_map_transactions.to_csv('output/map_transactions.csv', index=False)\n",
        "df_top_states.to_csv('output/top_states.csv', index=False)\n",
        "\n",
        "print(\"‚úÖ All data and visualizations saved to output/\")"
      ],
      "metadata": {
        "id": "2sfzb9pLdxbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e93e21-0423-47b0-9c66-4f32d005c897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All data and visualizations saved to output/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step: Save DataFrames to CSV for Streamlit\n",
        "#import os\n",
        "\n",
        "# Create output directory if not exists\n",
        "#os.makedirs('output', exist_ok=True)\n",
        "\n",
        "# Save all dataframes to CSV\n",
        "#df_agg_transactions.to_csv('output/agg_transactions.csv', index=False)\n",
        "#df_agg_users.to_csv('output/agg_users.csv', index=False)\n",
        "#df_map_transactions.to_csv('output/map_transactions.csv', index=False)\n",
        "#df_top_states.to_csv('output/top_states.csv', index=False)\n",
        "\n",
        "#print(\"‚úÖ All CSV files saved to output/\")"
      ],
      "metadata": {
        "id": "r13v9yxWVfW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. üñ•Ô∏è Build Streamlit Dashboard"
      ],
      "metadata": {
        "id": "9R-Afo3xdz7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File: dashboard.py (Updated with new visualizations)\n",
        "%%writefile dashboard.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import sys\n",
        "sys.path.append('src/')\n",
        "from visualization import *\n",
        "\n",
        "# Set page config with PhonePe theme\n",
        "st.set_page_config(\n",
        "    page_title=\"PhonePe Pulse Analytics\",\n",
        "    layout=\"wide\",\n",
        "    page_icon=\"üìä\"\n",
        ")\n",
        "\n",
        "# Apply custom CSS for consistent styling\n",
        "st.markdown(f\"\"\"\n",
        "    <style>\n",
        "        .main {{\n",
        "            background-color: {BACKGROUND_COLOR};\n",
        "        }}\n",
        "        .stApp {{\n",
        "            background-color: {BACKGROUND_COLOR};\n",
        "        }}\n",
        "        .css-18e3th9 {{\n",
        "            padding: 2rem;\n",
        "        }}\n",
        "        h1, h2, h3, h4, h5, h6 {{\n",
        "            color: {PHONEPE_COLORS[0]};\n",
        "        }}\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Main title\n",
        "st.title(\"üìä PhonePe Pulse Analytics Dashboard\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Sidebar navigation\n",
        "with st.sidebar:\n",
        "    st.image(\"https://www.phonepe.com/webstatic/static/phonepe-logo-white.svg\", width=150)\n",
        "    st.title(\"Navigation\")\n",
        "    option = st.radio(\"Select View\", [\n",
        "        \"Overview\",\n",
        "        \"Transaction Analysis\",\n",
        "        \"User Analysis\",\n",
        "        \"Geographical Analysis\",\n",
        "        \"Growth Metrics\"\n",
        "    ])\n",
        "\n",
        "# Load data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    return {\n",
        "        'agg_transactions': pd.read_csv('output/agg_transactions.csv'),\n",
        "        'agg_users': pd.read_csv('output/agg_users.csv'),\n",
        "        'map_transactions': pd.read_csv('output/map_transactions.csv'),\n",
        "        'top_states': pd.read_csv('output/top_states.csv')\n",
        "    }\n",
        "\n",
        "data = load_data()\n",
        "\n",
        "# Overview Page\n",
        "if option == \"Overview\":\n",
        "    st.subheader(\"üìå Key Insights at a Glance\")\n",
        "\n",
        "    # Create metrics row\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    total_trans = data['agg_transactions']['count'].sum()\n",
        "    total_users = data['agg_users']['total_registered_users'].sum()\n",
        "    avg_trans = data['agg_transactions']['amount'].sum() / data['agg_transactions']['count'].sum()\n",
        "    top_state = data['top_states'].groupby('state')['count'].sum().idxmax()\n",
        "\n",
        "    col1.metric(\"Total Transactions\", f\"{total_trans:,.0f}\")\n",
        "    col2.metric(\"Total Users\", f\"{total_users:,.0f}\")\n",
        "    col3.metric(\"Avg. Transaction Value\", f\"‚Çπ{avg_trans:,.2f}\")\n",
        "    col4.metric(\"Top Performing State\", top_state)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Show important charts in overview\n",
        "    st.subheader(\"üìà Transaction Trends\")\n",
        "    plot_transaction_trend(data['agg_transactions'])\n",
        "\n",
        "    st.subheader(\"üì± Top Device Brands\")\n",
        "    plot_device_usage(data['agg_users'])\n",
        "\n",
        "    st.subheader(\"üèÜ Top Performing States\")\n",
        "    plot_top_states(data['top_states'])\n",
        "\n",
        "# Transaction Analysis Page\n",
        "elif option == \"Transaction Analysis\":\n",
        "    st.subheader(\"üí∏ Transaction Analysis\")\n",
        "\n",
        "    tab1, tab2, tab3 = st.tabs([\"Trends\", \"Categories\", \"Metrics\"])\n",
        "\n",
        "    with tab1:\n",
        "        plot_transaction_trend(data['agg_transactions'])\n",
        "        plot_quarterly_growth(data['agg_transactions'])\n",
        "\n",
        "    with tab2:\n",
        "        plot_category_distribution(data['agg_transactions'])\n",
        "        plot_category_trends(data['agg_transactions'])\n",
        "\n",
        "    with tab3:\n",
        "        plot_avg_transaction_value(data['agg_transactions'])\n",
        "        plot_transaction_heatmap(data['agg_transactions'])\n",
        "\n",
        "# User Analysis Page\n",
        "elif option == \"User Analysis\":\n",
        "    st.subheader(\"üë• User Analysis\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        plot_user_growth(data['agg_users'])\n",
        "        plot_device_usage(data['agg_users'])\n",
        "\n",
        "    with col2:\n",
        "        plot_device_share_trend(data['agg_users'])\n",
        "\n",
        "# Geographical Analysis Page\n",
        "elif option == \"Geographical Analysis\":\n",
        "    st.subheader(\"üåç Geographical Analysis\")\n",
        "\n",
        "    plot_state_analysis(data['top_states'])\n",
        "    plot_top_districts(data['map_transactions'])\n",
        "    plot_state_map(data['top_states'])\n",
        "\n",
        "# Growth Metrics Page\n",
        "elif option == \"Growth Metrics\":\n",
        "    st.subheader(\"üìà Growth Metrics\")\n",
        "\n",
        "    plot_quarterly_growth(data['agg_transactions'])\n",
        "    plot_user_growth(data['agg_users'])"
      ],
      "metadata": {
        "id": "gGI9lBp1d0l6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea5c86c-b98a-4780-e617-9eb3f3e6e612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dashboard.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. üíæ Save DataFrames for Reuse"
      ],
      "metadata": {
        "id": "o0K-aL8kd3Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 6: Save DataFrames to CSV\n",
        "df_agg_transactions.to_csv('output/agg_transactions.csv', index=False)\n",
        "df_agg_users.to_csv('output/agg_users.csv', index=False)\n",
        "df_map_transactions.to_csv('output/map_transactions.csv', index=False)\n",
        "df_top_states.to_csv('output/top_states.csv', index=False)\n",
        "\n",
        "print(\"Data saved to output folder.\")"
      ],
      "metadata": {
        "id": "9L0TYtmZd4da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c2d8f4-5521-47bc-bc2d-c3055231162a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. ‚ñ∂Ô∏è Launch Streamlit Dashboard in Colab"
      ],
      "metadata": {
        "id": "p_JDM3RRd8BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Final Fixed dashboard.py\n",
        "%%writefile dashboard.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('src/')\n",
        "from visualization import *\n",
        "\n",
        "# Set page config with improved styling\n",
        "st.set_page_config(\n",
        "    page_title=\"PhonePe Pulse Analytics\",\n",
        "    layout=\"wide\",\n",
        "    page_icon=\"üìä\"\n",
        ")\n",
        "\n",
        "# PhonePe logo URL (using raw SVG for reliability)\n",
        "PHONEPE_LOGO = \"\"\"\n",
        "<svg width=\"150\" height=\"40\" viewBox=\"0 0 150 40\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
        "<path d=\"M30 10H20V30H30V10Z\" fill=\"#5F0F40\"/>\n",
        "<path d=\"M40 10H30V30H40V10Z\" fill=\"#9A031E\"/>\n",
        "<path d=\"M50 10H40V30H50V10Z\" fill=\"#FB8B24\"/>\n",
        "<path d=\"M60 10H50V30H60V10Z\" fill=\"#E36414\"/>\n",
        "<path d=\"M70 10H60V30H70V10Z\" fill=\"#0F4C5C\"/>\n",
        "<text x=\"80\" y=\"25\" font-family=\"Arial\" font-size=\"20\" font-weight=\"bold\" fill=\"#5F0F40\">PhonePe Pulse</text>\n",
        "</svg>\n",
        "\"\"\"\n",
        "\n",
        "# Apply custom CSS for perfect styling\n",
        "st.markdown(f\"\"\"\n",
        "    <style>\n",
        "        /* Main background */\n",
        "        .main, .stApp {{\n",
        "            background-color: #5F0F40;\n",
        "        }}\n",
        "\n",
        "        /* Text colors */\n",
        "        h1, h2, h3, h4, h5, h6 {{\n",
        "            color: white !important;\n",
        "            font-weight: 600 !important;\n",
        "        }}\n",
        "\n",
        "        /* Sidebar styling */\n",
        "        .css-1lcbmhc {{\n",
        "            background-color: #5F0F40 !important;\n",
        "        }}\n",
        "        .css-1lcbmhc h1,\n",
        "        .css-1lcbmhc .stRadio label {{\n",
        "            color: white !important;\n",
        "        }}\n",
        "\n",
        "        /* Chart background */\n",
        "        .stPlotlyChart, .plot-container {{\n",
        "            background-color: rgba(0, 0, 0, 0.5);\n",
        "            border-radius: 8px;\n",
        "            padding: 15px;\n",
        "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "        }}\n",
        "\n",
        "        /* Navigation radio buttons */\n",
        "        .stRadio div[role=\"radiogroup\"] {{\n",
        "            background-color: #6c1d5f;\n",
        "            padding: 10px;\n",
        "            border-radius: 8px;\n",
        "        }}\n",
        "        .stRadio label {{\n",
        "            color: white !important;\n",
        "            padding: 5px 10px;\n",
        "        }}\n",
        "        .stRadio label:hover {{\n",
        "            background-color: #9A031E !important;\n",
        "        }}\n",
        "\n",
        "        /* Remove the 0 below logo */\n",
        "        .css-1v3fvcr {{\n",
        "            display: none;\n",
        "        }}\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Main title\n",
        "st.title(\"üìä PhonePe Pulse Analytics Dashboard\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Sidebar navigation with proper logo\n",
        "with st.sidebar:\n",
        "    st.markdown(PHONEPE_LOGO, unsafe_allow_html=True)\n",
        "    st.markdown(\"<h1 style='color:white !important;'>Navigation</h1>\", unsafe_allow_html=True)\n",
        "    option = st.radio(\n",
        "        \"Menu\",\n",
        "        [\n",
        "            \"Overview\",\n",
        "            \"Transaction Analysis\",\n",
        "            \"User Analysis\",\n",
        "            \"Geographical Analysis\",\n",
        "            \"Advanced Insights\"\n",
        "        ],\n",
        "        index=0,\n",
        "        label_visibility=\"collapsed\"\n",
        "    )\n",
        "\n",
        "# Load data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    return {\n",
        "        'agg_transactions': pd.read_csv('output/agg_transactions.csv'),\n",
        "        'agg_users': pd.read_csv('output/agg_users.csv'),\n",
        "        'map_transactions': pd.read_csv('output/map_transactions.csv'),\n",
        "        'top_states': pd.read_csv('output/top_states.csv')\n",
        "    }\n",
        "\n",
        "data = load_data()\n",
        "\n",
        "# Overview Page\n",
        "if option == \"Overview\":\n",
        "    st.subheader(\"üìå Key Insights at a Glance\")\n",
        "\n",
        "    # Create metrics row\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    total_trans = data['agg_transactions']['count'].sum()\n",
        "    total_users = data['agg_users']['total_registered_users'].sum()\n",
        "    avg_trans = data['agg_transactions']['amount'].sum() / data['agg_transactions']['count'].sum()\n",
        "    top_state = data['top_states'].groupby('state')['count'].sum().idxmax()\n",
        "\n",
        "    col1.metric(\"Total Transactions\", f\"{total_trans:,.0f}\")\n",
        "    col2.metric(\"Total Registered Users\", f\"{total_users:,.0f}\")\n",
        "    col3.metric(\"Avg. Transaction Value\", f\"‚Çπ{avg_trans:,.2f}\")\n",
        "    col4.metric(\"Top Performing State\", top_state)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Show important charts in overview\n",
        "    st.subheader(\"üìà Key Transaction Trends\")\n",
        "    plot_transaction_trend(data['agg_transactions'])\n",
        "\n",
        "    st.subheader(\"üì± Top Device Brands\")\n",
        "    plot_device_usage(data['agg_users'])\n",
        "\n",
        "    st.subheader(\"üèÜ Top Performing States\")\n",
        "    plot_top_states(data['top_states'])\n",
        "\n",
        "# Transaction Analysis Page\n",
        "elif option == \"Transaction Analysis\":\n",
        "    st.subheader(\"üí∏ Transaction Analysis\")\n",
        "\n",
        "    tab1, tab2, tab3 = st.tabs([\"Trends\", \"Categories\", \"Metrics\"])\n",
        "\n",
        "    with tab1:\n",
        "        st.subheader(\"Transaction Volume Over Time\")\n",
        "        plot_transaction_trend(data['agg_transactions'])\n",
        "\n",
        "        st.subheader(\"Quarterly Growth Rates\")\n",
        "        plot_quarterly_growth(data['agg_transactions'])\n",
        "\n",
        "    with tab2:\n",
        "        st.subheader(\"Transaction Distribution by Category\")\n",
        "        plot_category_distribution(data['agg_transactions'])\n",
        "\n",
        "        st.subheader(\"Category Trends Over Time\")\n",
        "        plot_category_trends(data['agg_transactions'])\n",
        "\n",
        "    with tab3:\n",
        "        st.subheader(\"Average Transaction Values\")\n",
        "        plot_avg_transaction_value(data['agg_transactions'])\n",
        "\n",
        "        st.subheader(\"Transaction Heatmap\")\n",
        "        plot_transaction_heatmap(data['agg_transactions'])\n",
        "\n",
        "# User Analysis Page\n",
        "elif option == \"User Analysis\":\n",
        "    st.subheader(\"üë• User Behavior Analysis\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"User Growth Over Time\")\n",
        "        plot_user_growth(data['agg_users'])\n",
        "\n",
        "        st.subheader(\"Top Device Brands\")\n",
        "        plot_device_usage(data['agg_users'])\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Device Brand Trends\")\n",
        "        plot_device_share_trend(data['agg_users'])\n",
        "\n",
        "# Geographical Analysis Page\n",
        "elif option == \"Geographical Analysis\":\n",
        "    st.subheader(\"üåç Geographical Distribution\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"Top Performing States\")\n",
        "        plot_top_states(data['top_states'])\n",
        "\n",
        "        st.subheader(\"State Performance Analysis\")\n",
        "        plot_state_analysis(data['top_states'])\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Top Districts by Volume\")\n",
        "        plot_top_districts(data['map_transactions'])\n",
        "\n",
        "# Advanced Insights Page\n",
        "elif option == \"Advanced Insights\":\n",
        "    st.subheader(\"üîç Advanced Analytics\")\n",
        "\n",
        "    st.subheader(\"Transaction Category Trends\")\n",
        "    plot_category_trends(data['agg_transactions'])\n",
        "\n",
        "    st.subheader(\"Device Brand Evolution\")\n",
        "    plot_device_share_trend(data['agg_users'])\n",
        "\n",
        "    st.subheader(\"Transaction Value Analysis\")\n",
        "    plot_avg_transaction_value(data['agg_transactions'])\n",
        "\n",
        "    st.subheader(\"Quarterly Performance Heatmap\")\n",
        "    plot_transaction_heatmap(data['agg_transactions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXXA5tSjV2b7",
        "outputId": "04e4f7c8-2e56-49a7-91d0-f2af9464cf94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dashboard.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project demonstrates how to:\n",
        "\n",
        "Extract and process raw JSON data from the PhonePe Pulse repository.\n",
        "Perform exploratory data analysis using Pandas.\n",
        "Visualize key business metrics using Matplotlib and Seaborn.\n",
        "Build an interactive dashboard using Streamlit."
      ],
      "metadata": {
        "id": "r1KKBy0BeEV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93YBdTsP5HUI",
        "outputId": "45ca1bf9-d81d-4f0c-8bef-011882cb8a9d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the ngrok authtoken from Colab secrets\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "else:\n",
        "    print(\"NGROK_AUTH_TOKEN not found in Colab secrets. Please add it.\")\n",
        "\n",
        "\n",
        "# Run Streamlit in the background\n",
        "!streamlit run dashboard.py &>/dev/null&\n",
        "\n",
        "# Get the public URL\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print(\"Streamlit Dashboard URL:\")\n",
        "print(public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1hueiH25L6o",
        "outputId": "d86b5ac8-3c35-4948-d7c6-137a2c40dba1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit Dashboard URL:\n",
            "NgrokTunnel: \"https://ea7f-35-231-158-192.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok"
      ],
      "metadata": {
        "id": "WFKpDSSuR5OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run dashboard.py &>/dev/null&\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print(\"Dashboard URL:\", public_url)"
      ],
      "metadata": {
        "id": "ShMw0pU3R8Sc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}